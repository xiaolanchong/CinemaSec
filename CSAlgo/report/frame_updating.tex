%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Процедура обновления текущего изображения}
\label{sec:frame_updating}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
Традиционным способом борьбы с шумами в системах реального времени является следующая формула обновления текущего кадра
%
\begin{equation}
\label{eq:frame_updating}
I^{t}(x,y) = a \, I^{t-1}(x,y) + (1-a) F^{t}(x,y),
\end{equation}
%
где $t$ это дискретное время, $I^{t-1}(x,y)$ это значение яркости в точке $(x,y)$ предыдущего изображения, $F^{t}(x,y)$ это значение яркости в точке $(x,y)$ вновь поступившего кадра, $I^{t}(x,y)$ это значение нового изображения в точке $(x,y)$, полученное суммированием текущего кадра с ранее накопленными кадрами, а коэффициент $a$ есть величина задающая скорость обновления (updating rate), $a \in (0,1)$. Легко показать, что формула (\ref{eq:frame_updating}) эквивалентна свертке по времени $t$ с некоторым экспоненциальным фильтром, действительно
%
\begin{eqnarray*}
I^{t}(x,y) &=& a I^{t-1}(x,y) + (1-a) F^{t}(x,y) \\
           &=& a (a I^{t-2}(x,y) + (1-a) F^{t-1}(x,y)) + (1-a) F^{t}(x,y) \\
           &=& a (a (a I^{t-3}(x,y) + (1-a) F^{t-2}(x,y)) + (1-a) F^{t-1}(x,y)) + (1-a) F^{t}(x,y) \\
           &=& \ldots \,\, \mbox{\emph{k} times} \,\, \ldots \\
           &=& a^k I^{t-k}(x,y) + (1-a) \sum _{i=0}^{k-1} a^i F^{t-i}(x,y) \\
           & \mathop = \limits _{k \rightarrow \infty}& (1-a) \sum _{i=0}^{\infty} a^i F^{t-i}(x,y).
\end{eqnarray*}
%
Из последней формулы видно, что при $a=\exp(-\gamma){\,}<{\,}1$ мы имеем дело с фильтром типа $\exp(-{\gamma}t)$, сглаживающим интенсивность в каждой точке $(x,y)$ по времени.

Простейший подход состоит в задании параметра $a$ в виде константы, значение которой взято из опыта. Этот подход не оптимален в условиях когда скорость подачи новых кадров (frame rate) сильно непостоянна. Чтобы как-то сгладить эффект непостоянства скорости кадров мы адаптивно подбирали параметр $a$ на каждой итерации
%
\[ a = \exp \left( -\frac{\Delta t}{\tau} \right), \]
%   
где $\Delta t$ есть время прошедшее между подачей двух последних кадров, а параметр $\tau$ регулирует величину временного сглаживания и задаётся по результатам экспериментов. Такой подход был применён нами в первой версии алгоритма.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Обновление до заданного отношения сигнал/шум}
\label{sec:augment-signal-noise}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
К сожалению, в условиях слабого освещения, имеющего место во время киносеанса, изображение оказывается столь зашумлено, а интенсивность столь мала, что на первое место выходят другие критерии выбора параметра $a$. В настоящем разделе мы рассмотрим следующую задачу: \emph{найти такой параметр $a$, который обеспечивает заданное отношение сигнал/шум}. Очевидно, что ``вытянуть'' нужное отношение сигнал/шум можно только за счёт большего накопления кадров, т.е. за счёт ухудшения динамики (смазывания) картинки в тех местах, где объекты интенсивно движутся. Это потребовало изменить другие части алгоритма слежения за объектами в зале кинотеатра. В частности, мы отказались от слежения за текущим движением объекта (алгоритм 1) и перешли к анализу изменчивости поз, принимаемых человеком сидящим в кресле.

В общем случае значения яркости в точках изображения состоят из идеальных (незашумлённых) значений интенсивности и аддитивного шума. Перепишем уравнение (\ref{eq:frame_updating}) с учётом шумов, предполагая что значения $I^{t}(x,y)$, $I^{t-1}(x,y)$ и $F^{t}(x,y)$ теперь соответствуют идеальным (незашумлённым, но неизвестным) значениям интенсивности
%
\begin{equation}
\label{eq:noisy_frame_updating}
I^{t}(x,y)+n^{t}(x,y) = a (I^{t-1}(x,y)+n^{t-1}(x,y)) + (1-a) (F^{t}(x,y)+{\nu}^{t}(x,y)) ,
\end{equation}
%
где $n^{t}(x,y)$ и $n^{t-1}(x,y)$ это величины остаточных (после временного сглаживания) аддитивных шумов изображения в моменты $t$ и $t-1$ соответственно, а ${\nu}^{t}(x,y)$ это величина аддитивного шума вновь поступившего кадра. В работе \cite{Akhriev04} мы рассмотрели полиномиальные маски, которые отфильтровывают регулярную часть изображения (в нашем случае это $I^{t}$, $I^{t-1}$ и $F^{t}$) и оставляют шумовую компоненту. В простейшем случае маска выглядит следующим образом
%
\begin{equation}
\label{eq:noise-mask}
M_{2{\times}2} = \left[ {\begin{array}{cc} {+1} & {-1} \\ {-1} & {+1} \\ \end{array}} \right] . \end{equation}
%
Допустим, что идеальное (незашумлённое) изображение $I(x,y)$ локально представимо в виде кусочно-линейной функции $I(x,y){\,\approx\,}{Ax+By+C}$. Сами величины $A$, $B$ и $C$ нам, естественно, не известны. Для большинства осмысленных изображений это представление достаточно точно, за исключением быть может резких световых переходов. Прямым вычислением легко показать, что свёртка с маской $M_{2{\times}2}$ аннулирует кусочно-линейную часть функции интенсивности $I(x,y)$ для любых значений $A$, $B$ и $C$. Всё что остаётся после свёртки трактуется как шум. Такая трактовка не совсем корректна (при наличии значительных текстурированных участков и статистической зависимости шума в соседних пикселах), однако для оценочных расчётов вполне уместна. В результате применения полиномиальной маски к изображениям, уравнение (\ref{eq:noisy_frame_updating}) становится уравнением эволюции шума
%
\[ n^{t}(x,y) = a n^{t-1}(x,y) + (1-a) {\nu}^{t}(x,y) . \]
%
Умножим обе части последнего уравнения сами на себя и усредним полученные квадратичные значения по всем точкам $(x,y)$
%
\[ \langle n^t n^t \rangle = a^2 \langle n^{t-1} n^{t-1} \rangle +
                             (1-a)^2 \langle {\nu}^{t}(x,y) {\nu}^{t}(x,y) \rangle +
                             2 a (1-a) \langle n^{t-1} {\nu}^{t}(x,y) \rangle . \]
%
В установившемся (стационарном) режиме можно считать что шум изображения не меняется, а шумовые характеристики вновь поступающих кадров почти неизменны, т.е. 
%
\[ \sigma _n^2 = {\langle n^t n^t \rangle} = {\langle n^{t-1} n^{t-1} \rangle} , \]
%
где через ${\sigma}_n$ обозначена девиация шума изображения в стационарном режиме. Кроме того, шум вновь поступившего кадра статистически независим от шумов предыдущих кадров, что обусловлено свойством ПЗС камеры, поэтому
%
\[ \langle n^{t-1} {\nu}^{t}(x,y) \rangle = 0 . \]
%
Обозначая через $s_n$ девиацию шума вновь поступающих кадров ($s_n^2$ = $\langle {\nu}^{t}(x,y) {\nu}^{t}(x,y) \rangle$), приходим к следующему соотношению
%
\[ \sigma _n^2 = a^2 \sigma _n^2 + (1-a)^2 s_n^2 , \]
%
откуда немедленно следует
%
\begin{equation}
\label{eq:sigma_noise}
\sigma _n^2 = \frac{1-a}{1+a} s_n^2 .
\end{equation}        
%
Обозначим через $\sigma _i$ девиацию результирующего изображения $I^t$, измеряемую на каждой итерации
%
\[ \sigma _i^2 = \langle (I^t)^2 \rangle - {\langle I^t \rangle}^2 . \]
%
Естественно считать величину $\sigma _i$ уровнем сигнала (можно, впрочем, использовать и среднюю амплитуду интенсивности). Мы хотим так выбирать параметр $a$, чтобы в любой момент времени выполнялось следующее неравенство
%
\begin{equation}
\label{eq:sn-ratio-inequality}
r^2 = \frac{{\sigma _i^2 }}{{\sigma _n^2 }} =
\frac{{1 + a}}{{1 - a}} \,\, \frac{{\sigma _i^2 }}{{s_n^2 }} \,\, \ge \,\, r_0^2 ,
\end{equation}  
%
где через $r$ обозначено отношение сигнал/шум результирующего изображения $I^t$, а через $r_0$ обозначено минимальное отношение сигнал/шум, которое мы \textit{желаем} получить на выходе. Последнее значение задаётся \textit{вручную}. После несложных преобразований получаем искомое значение коэффициента обновления $a_0$, обеспечивающего заданное отношение сигнал/шум
%
\begin{equation}
\label{eq:sn-ratio-inequality3}
a \,\, \ge \,\, a_0 = \frac{r_0^2 - \frac{\sigma _i^2}{s_n^2}}{r_0^2 + \frac{\sigma _i^2}{s_n^2}} .
\end{equation}  
%
Значения ${\sigma}_i$ и $s_n$ постоянно измеряются на каждом шаге обновления по формуле (\ref{eq:frame_updating}). В реальности они, конечно, нестационарные. Однако неплохим приближением будет предположение о квазистационарности, особенно если ограничить значение параметра $a$ во избежании резких скачков
%
\begin{equation}
\label{eq:a-updating-parameter}
a = \max \left( a_0, \frac{1}{2} \right) .
\end{equation}
%
Полученное в текущий момент $t$ значение $a$ используется на следующем шаге в формуле (\ref{eq:frame_updating}) в момент $t+1$. Формула (\ref{eq:a-updating-parameter}) гарантирует нам, что в процессе обновления будут всегда присутствовать предыдущие кадры ($a\,{\geq}\,\frac{1}{2}$), т.е. процесс обновления будет обладать некоторой инерционностью, приближающей нас к гипотезе о квазистационарности. Кроме того, формула (\ref{eq:a-updating-parameter}) страхует нас от отрицательных значений $a_0$, которые могут возникнуть если отношение сигнал/шум во вновь поступившем кадре $F^t$ изначально достаточно велико (больше чем пороговое значение $r_0$).
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Усиление робастности процедуры обновления}
\label{sec:robust-update}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
Во время киносеанса экран часто резко вспыхивает и столь же резко гаснет (резкая смена сюжета, взрыв, стрельба и т.п.). Это нарушает гипотезу квазистационарности видеопоследовательности, смещая оптимальную оценку параметра обновления $a$, полученного по формуле (\ref{eq:sn-ratio-inequality3}). Чтобы ослабить влияние резких перепадов яркости мы будет подавать в формулу (\ref{eq:frame_updating}) не исходный кадр $F^t$, а предобработанный ${\tilde F}^t$
%
\begin{equation}
\label{eq:robast-update}
{\tilde F}^t(x,y) = I^t(x,y) + (F^t(x,y) - I^t(x,y)) \left(
  \frac{\sigma ^p_t}{\sigma ^p_t + \left| F^t(x,y)-I^t(x,y) \right|^p} \right)^{\frac{1}{p}},
\end{equation}
%
где $I^t(x,y)$ есть значение интенсивности в точке $(x,y)$, полученное в результате накопления, см. (\ref{eq:frame_updating}), к моменту времени $t$, а ${\sigma}_t$ есть оценка отклонения от временного среднего $I^t(x,y)$. Параметр $p$ обычно равен 1 или 2, в зависимоти от выбранной модели.

Смысл формулы (\ref{eq:robast-update}) заключён в коэффициенте $c=({{\sigma}^p_t}/({\sigma}^p_t{+}|{F^t-I^t}|^p))^{\frac{1}{p}}$. Если $|{F^t-I^t}|{\ll}{\sigma}_t$, то $c{\approx}1$ и ${\tilde{F}}^t(x,y){\approx}F^t(x,y)$, т.е. кадр подаётся почти без изменений. В противном случае ($|{F^t-I^t}|{\gg}{\sigma}_t$) отклонение от временного среднего $I^t(x,y)$ сильно ограничивается ${\tilde{F}}^t(x,y){\approx}F^t(x,y)+{{\sigma}_t}{\,}\mbox{sign}(F^t-I^t)$. Иными словами, чем сильнее исходный кадр $F^t(x,y)$ отличается от временного среднего $I^t(x,y)$, тем сильнее он ограничивается, причем абсолютная величина отклонения не может превысить девиацию ${\sigma}_t$. Девиация вычисляется в каждой точке в отдельности ${\sigma}_t={\sigma}_t(x,y)$. Само временное среднее преобразуется по формуле аналогичной (\ref{eq:frame_updating})
%
\begin{equation}
\label{eq:robust-frame-updating}
I^t(x,y) = a \, I^{t-1}(x,y) + (1-a) {\tilde F}^t(x,y),
\end{equation}
%
\noindent девиация ${\sigma}_t$ преобразуется по следующей формуле ($p=1,2$)
%
\begin{equation}
\label{eq:deviation-updating}
{\sigma}^p_{t+1}(x,y) = a \, {\sigma}^p_t(x,y) +
                     (1-a) \left| {\tilde F}^t(x,y) - I^t(x,y) \right|^p,
\end{equation}
%
\noindent а коэффициент обновления $a$ вычисляется как прежде, см. (\ref{eq:sn-ratio-inequality3}), (\ref{eq:a-updating-parameter}).

Преобразование входного кадра по формуле (\ref{eq:robast-update}) даёт более стабильную картинку, однако если значение ${\sigma}_t$ мало, наблюдается т.н. ``схлопывание''. Этот эффект подобен попаданию в ловушку. Чем меньше ${\sigma}_t$, тем меньше ${\tilde{F}}^t(x,y)$ отличается от $I^t(x,y)$, тем, в свою очередь, меньше ${\sigma}_t$ полученное из (\ref{eq:deviation-updating}), и т.д. пока не произойдет обнуление ${\sigma}_t=0$. Чтобы избежать подобной ситуации мы, во-первых, полагаем ${\sigma}_t=\max{({\sigma}_t,1)}$. Во-вторых, в формуле (\ref{eq:robast-update}) мы используем масштабированное значение девиации $1.5{\div}2.5{\,}{\sigma}_t$.

Как мы надеемся, робастное обновление изображения позволит нам в будущем применить алгоритмы детекции движения, как это делается в системе \orwell2. Тогда появится гипотетическая возможность прослеживать перемещение объектов по залу. Для этого было бы желательно получить теоретические оценки на минимальное значение девиации и минимальный коэффициент масштабирования, которые гарантировали бы отсутствие ``схлопывания''.

В данный момент метод робастного обновления реализован во второй версии алгоритма. Метод работает стабильно, но из-за теоретической опасности ``схлопывания'' мы предпочитаем (пока) использовать более традиционный подход, описанный в начале этого раздела. 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Процедуры обновления на основе фильтра Калмана}
\label{sec:kalman-update}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
Ещё один метод обновления был реализован на основе калмановского фильтра. Следую изложению данному в работах \cite{Welch95,Welch01}, будет считать, что процесс эволюции состояния ${\bf{x}}_t$ системы описывается линейным стохастическим уравнением первого порядка
%
\begin{equation}
\label{eq:kalman-stoch-eq}
{\bf x}_t = {\bf A} {\bf x}_{t-1} + {\bf w}_{t-1},
\end{equation}
%
\noindent а результат измерения ${\bf{z}}_t$ линейно зависит от текущего состояния ${\bf{x}}_t$
%
\begin{equation}
\label{eq:kalman-measurement}
{\bf z}_t = {\bf H} {\bf x}_t + {\bf v}_t,
\end{equation}
%
\noindent где ${\bf{A}}$ и ${\bf{H}}$ являются матрицами, ${\bf{w}}$ и ${\bf{v}}$ есть нормально-распределённые шумы предсказания и измерения соответственно с нулевыми средними и ковариационными матрицами ${\bf{Q}}$ и ${\bf{R}}$
%
\begin{eqnarray*}
p({\bf w}) & \sim & {\cal N}(0,{\bf Q}), \\
p({\bf v}) & \sim & {\cal N}(0,{\bf R}).
\end{eqnarray*}
%
\noindent В общем случае состояние ${\bf{x}}_t$, измерение ${\bf{z}}_t$ и шумы описываются векторами (не обязательно одинаковой размерности).

Упрощённо механизм работы фильтра Калмана можно представить следующим образом. Если шум измерения велик, то апострериорная оценка состояния полагается в основном на предсказание (\ref{eq:kalman-stoch-eq}), исходя из предыдущей оценки ${\bf{x}}_{t-1}$. И наоборот, если велика неопределённость предсказания, то наибольший вклад в апострериорную оценку вносит измерение ${\bf{z}}_t$ (\ref{eq:kalman-measurement}). Более точные формулировки можно найти в \cite{Welch95,Welch01}. Процесс синтеза апострериорной оценки состояния выглядит следующим образом
%
\begin{enumerate}
\itemsep = -\parsep
\item Получить начальные оценки ($t=0$):
${\bf \hat x}_0$ и ${\bf P}_0$.
\item Получить априорное значение состояния:
${\bf \hat x}^{-}_t = {\bf A} {\bf \hat x}^{-}_{t-1}$.
\item Получить априорную ковариационную матрицу:
${\bf P}^{-}_t = {\bf A} {\bf P}_{t-1} {\bf A}^{T} + {\bf Q}$.
\item Вычислить матрицу выигрыша (gain):
${\bf K}_t = {\bf P}^{-}_t {\bf H}^T \left( {\bf H} {\bf P}^{-}_t {\bf H}^T + {\bf R} \right)^{-1}$.
\item Обновить оценку с учётом измерения ${\bf z}_t$:
${\bf \hat x}_t = {\bf \hat x}^{-}_t + {\bf K}_t
                    \left( {\bf z}_t - {\bf H} {\bf \hat x}^{-}_t \right)$.
\item Обновить ковариационную матрицу:
${\bf P}_t = \left( {\bf I} - {\bf K}_t {\bf H} \right) {\bf P}^{-}_{t}$.
\item $t=t+1$. Продолжить с пункта 2.
\end{enumerate}

В нашем частном случае, состояние есть значение интенсивности в данной точке $(x,y)$. Таким образом, в каждой точке работает отдельный калмановский фильтр. Соответсвенно все матрицы и вектора имеют единичную размерность. Перепишем стохастическое уравнение и уравнение измерения с учётом условий нашей задачи
%
\begin{eqnarray*}
\label{eq:our-kalman}
I_t(x,y) &=& I_{t-1}(x,y) + w_{t-1}(x,y) , \\
F_t(x,y) &=& I_t(x,y) + v_t(x,y)         , \\
p(w) & \sim & {\cal N}( 0, \sigma _w )   , \\
p(v) & \sim & {\cal N}( 0, \sigma _v )   ,
\end{eqnarray*}
%
\noindent где $I_t(x,y)$ и $I_{t-1}(x,y)$ есть интенсивности отфильтрованного (сглаженного) изображения в точке $(x,y)$ в моменты $t$ и $t-1$ соответственно, $F_t(x,y)$ есть входной кадр (измерение), а ${\sigma}_w$ и ${\sigma}_v$ есть девиации соответсвующих шумовых процессов.

Девиации шумов оцениваются прямым измерением, в предположении того, что шумовые процессы в каждой точке имеют одинаковые параметры
%
\begin{eqnarray*}
\sigma _w &=& \left\langle {\left| {I_t(x,y) - I_{t-1}(x,y)} \right|} \right\rangle _{x,y}  \\ 
\sigma _v &=& \left\langle {\left| {F_t(x,y) - F_{t-1}(x,y)} \right|} \right\rangle _{x,y} 
\end{eqnarray*}
%
\noindent где скобки ${\left\langle{.}\right\rangle}_{x,y}$ означают усреднение по всему изображению. Вычисление среднего модуля отклонения вместо среднего квадрата отклонения придаёт робастности оценкам девиаций.

Достоинством калмановского фильтра является оптимальное временное сглаживание, которое, с одной стороны, достаточно сильно подавляет шумы, а с другой стороны не даёт чрезмерного смаза картинки при движении объекта. Недостатком калмановского фильтра является неадекватная реакция на резкое изменение интенсивности, что не удивительно, т.к. калмановский фильтр предполагает нормальное распределение входного сигнала. При резкой смене освещённости в зале (вспышка на экране и т.п.) калмановский фильтр перестраивается заметное время. Чтобы ослабить влияние резких световых перепадов, мы реализовали во второй версии алгоритма \textit{робастный} фильтр Калмана, ограничив входной кадр по формуле (\ref{eq:robast-update}).
